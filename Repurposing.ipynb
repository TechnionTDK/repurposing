{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First, we define some utility fundtions for saving and loading objects from pickle.\n",
    "This code can be found in util.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open( name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build the text based graph. The code can be found in createSemRepGraph.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pn\n",
    "import graph_tool.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defuning some utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPathMaxPageRank(path):\n",
    "    pr = []\n",
    "    for p in path:\n",
    "        pr.append(pagerank[p])\n",
    "    return max(pr)\n",
    "\n",
    "\n",
    "def getPathNames(path):\n",
    "    pathStrArry = []\n",
    "    for p in path:\n",
    "        txt = IdToStrDict[p]\n",
    "        pathStrArry.append(txt)\n",
    "    return pathStrArry\n",
    "\n",
    "\n",
    "def printPageRankHist(semRepGraph):\n",
    "    prarry = []\n",
    "    for n in semRepGraph.nodes():\n",
    "        prarry.append(pagerank[n])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a graph and defining properties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semRepGraph = graph_tool.Graph()\n",
    "text_property = semRepGraph.new_vertex_property(\"string\")\n",
    "semRepGraph.vertex_properties['text'] = text_property\n",
    "\n",
    "semType_property = semRepGraph.new_vertex_property(\"string\")\n",
    "semRepGraph.vertex_properties['semType'] = semType_property\n",
    "\n",
    "cui_property = semRepGraph.new_vertex_property(\"string\")\n",
    "semRepGraph.vertex_properties['cui'] = cui_property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now read a csv file containing the PREDICATE table from SemRep (see: https://semrep.nlm.nih.gov/).\n",
    "We shall add vertoces and edges to the graph based on this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicates = pn.read_csv('/my_folder/SemRep.txt') \n",
    "predicates.columns = ['PREDICATION_ID', 'SENTENCE_ID', 'PMID', 'PREDICATE', 'SUBJECT_CUI', 'SUBJECT_NAME',\n",
    "                      'SUBJECT_SEMTYPE',\n",
    "                      'SUBJECT_NOVELTY', 'OBJECT_CUI', 'OBJECT_NAME', 'OBJECY_SEMTYPE', 'OBJECT_NOVELTY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTypes = ['CAUSES']\n",
    "predicates = predicates[predicates['PREDICATE'].isin(predTypes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can also be filtered by OBJECT_SEMTYPE and SUBJECT_SEMTYPE.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semtypes=['orgm','bpoc','diap','ortf','bsoj','inpo','tisu','topp','mamm','inpr','geoa','hlca','bdsy','blor','hcro','lbpr'\n",
    "          ,'inbe','orga','menp','mnob','humn','amph','plnt','spco','anim','resa','anab','eehu','tmco','edac','ftcn','ocdi',\n",
    "          'dora','qnco','orgt','npop','qlco','podg','prog','bird','mcha','rept','fish','phob','socb','idcn','popg',\n",
    "          'bmod','emod','aggp','famg','rnlw','mbrt','pros','lang','ocac','gora','medd']\n",
    "\n",
    "predicates = predicates[predicates['OBJECT_SEMTYPE'].isin(semtypes)==False]\n",
    "predicates = predicates[predicates['SUBJECT_SEMTYPE'].isin(semtypes)==False]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeDict = {}\n",
    "\n",
    "subjects = predicates['SUBJECT_NAME'].unique()\n",
    "objects = predicates['OBJECT_NAME'].unique()\n",
    "nodes = list(set(subjects).union(set(objects)))\n",
    "for n in nodes:\n",
    "    newNode = semRepGraph.add_vertex()\n",
    "    text_property[newNode] = n\n",
    "    nodeDict[n] = int(newNode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an edge for each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "edges = []\n",
    "while index < len(predicates):\n",
    "    print(index)\n",
    "    object = nodeDict[predicates.iloc[index]['SUBJECT_NAME']]\n",
    "    subject = nodeDict[predicates.iloc[index]['OBJECT_NAME']]\n",
    "    edges.append((object, subject))\n",
    "    index += 1\n",
    "\n",
    "semRepGraph.add_edge_list(edges)\n",
    "\n",
    "graph_tool.stats.remove_self_loops(semRepGraph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semRepGraph.save(\"/my_folder/semRepGraph.xml\")  # save garph\n",
    "save_obj(nodeDict, \"/my_folder/nodeDict\")  # save dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read graph and dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semRepGraph = graph_tool.load_graph(\"/my_folder/semRepGraph.xml\")\n",
    "nodeDict = load_obj(\"/my_folder/nodeDict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init IdTpStrDict\n",
    "IdToStrDict = {}\n",
    "for k in nodeDict.keys():\n",
    "    IdToStrDict[nodeDict[k]] = k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = nodeDict['Hydroxymethylglutaryl-CoA Reductase Inhibitors']\n",
    "t = nodeDict['Blood Pressure']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find paths. In this example, we look at paths with cutoff=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = graph_tool.topology.all_paths(semRepGraph, s, t, cutoff=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now go over the paths.\n",
    "While we go over them we can \"translate\" the node names to text.\n",
    "We can also rank or filter the paths  the paths. In this example, we calculate the max pagerank for each path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank = graph_tool.centrality.pagerank(semRepGraph) #for ranking\n",
    "\n",
    "\n",
    "textpaths = pn.DataFrame()\n",
    "prarray = []  # will hold max page rank for each path\n",
    "for p in paths:\n",
    "    prarray.append(getPathMaxPageRank(p))\n",
    "    textpaths = textpaths.append(pn.DataFrame([getPathNames(p)]))\n",
    "\n",
    "textpaths = textpaths.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "textpaths now holds all the reasoning paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textpaths.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
